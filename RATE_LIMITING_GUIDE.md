# ๐ฆ ุฏููู ุญู ูุดููุฉ Rate Limiting - AI Agent

## ๐ **ุงููุดููุฉ ุงูููุชุดูุฉ:**

**ุงูุฎุทุฃ:** `429 Too Many Requests` ูู OpenAI API  
**ุงูุณุจุจ:** ุชุฌุงูุฒ ุญุฏ ุงูุงุณุชุฎุฏุงู ุงููุณููุญ ูู OpenAI

---

## โ **ุงูุญููู ุงููุทุจูุฉ:**

### 1. **Rate Limiting ุนูู ูุณุชูู Django:**

ุชู ุฅุถุงูุฉ ุญูุงูุฉ ูู ุงูุทูุจุงุช ุงููุซูุฑุฉ:

```python
# ai_agent/throttling.py
- 10 ุทูุจุงุช ูู ุงูุฏูููุฉ ูููุณุชุฎุฏููู ุงููุตุฑุญ ููู
- 5 ุทูุจุงุช ูู ุงูุฏูููุฉ ูููุณุชุฎุฏููู ุบูุฑ ุงููุตุฑุญ ููู
- ุญูุงูุฉ ูู Burst requests
```

### 2. **ูุนุงูุฌุฉ ุฃุฎุทุงุก ูุญุณูุฉ:**

```python
# ai_agent/error_handler.py
โ ุฑุณุงุฆู ุฎุทุฃ ุนุฑุจูุฉ ูุงุถุญุฉ
โ ูุนุงูุฌุฉ ุฎุงุตุฉ ูู Rate Limit (429)
โ ูุนุงูุฌุฉ ุฎุงุตุฉ ูู Auth errors (401)
โ ูุนุงูุฌุฉ ุฎุงุตุฉ ูู Service errors (502/503)
```

### 3. **ุฑุณุงุฆู ูุณุชุฎุฏู ูุงุถุญุฉ:**

**ุจุฏูุงู ูู:**
```json
{
  "error": "Internal Server Error 500"
}
```

**ุงูุขู:**
```json
{
  "error": "ุชู ุชุฌุงูุฒ ุญุฏ ุงูุงุณุชุฎุฏุงู ุงููุคูุช ููุฎุฏูุฉ",
  "message": "ูุฑุฌู ุงูุงูุชุธุงุฑ ููููุงู ูุงููุญุงููุฉ ูุฑุฉ ุฃุฎุฑู",
  "error_code": "RATE_LIMIT_EXCEEDED",
  "retry_after": 60
}
```

---

## ๐๏ธ **ุญููู ุฅุถุงููุฉ ููุตู ุจูุง:**

### 1. **Caching ููุฑุฏูุฏ ุงูุดุงุฆุนุฉ:**

```python
# ุงุณุชุฎุฏุงู Redis ูุชุฎุฒูู ุงูุฑุฏูุฏ ุงููุชูุฑุฑุฉ
from django.core.cache import cache

def get_cached_response(message):
    cache_key = f"ai_response:{hash(message)}"
    cached = cache.get(cache_key)
    if cached:
        return cached
    # ... call OpenAI
    cache.set(cache_key, response, timeout=3600)  # 1 hour
```

### 2. **Queue System ููุทูุจุงุช:**

```python
# ุงุณุชุฎุฏุงู Celery ููุนุงูุฌุฉ ุงูุทูุจุงุช ุจุดูู ุชุณูุณูู
@celery_app.task(rate_limit='10/m')
def process_ai_request(user_id, message):
    # ูุนุงูุฌุฉ ุงูุทูุจ
    pass
```

### 3. **ุฒูุงุฏุฉ ุญุฏูุฏ OpenAI:**

- ุชุฑููุฉ ุงูู API tier ูู OpenAI
- ุฒูุงุฏุฉ ุงูู RPM (Requests Per Minute)
- ุฒูุงุฏุฉ ุงูู TPM (Tokens Per Minute)

### 4. **Load Balancing:**

```python
# ุงุณุชุฎุฏุงู ุฃูุซุฑ ูู API key ูุชูุฒูุน ุงูุทูุจุงุช
OPENAI_API_KEYS = [
    'key1',
    'key2',
    'key3'
]

# Round-robin between keys
```

---

## ๐ **ุญุฏูุฏ OpenAI ุงูุญุงููุฉ:**

| Plan | RPM | TPM | TPD |
|------|-----|-----|-----|
| Free | 3 | 40,000 | 200 |
| Tier 1 | 500 | 60,000 | 10,000 |
| Tier 2 | 5,000 | 160,000 | 50,000 |
| Tier 3 | 10,000 | 1,000,000 | 200,000 |

---

## ๐ง **ููููุฉ ุงูุชุทุจูู:**

### ุนูู ุงูุณูุฑูุฑ:

```bash
# 1. Pull ุงูุชุญุฏูุซุงุช
cd /opt/pharmasky
git pull origin main

# 2. ุฅุนุงุฏุฉ build
docker-compose down
docker-compose build --no-cache

# 3. ุฅุนุงุฏุฉ ุงูุชุดุบูู
docker-compose up -d

# 4. ุงูุชุญูู
docker-compose logs web --tail=50
```

---

## ๐ **ุชุนุฏูู ุงูุญุฏูุฏ:**

ูุชุนุฏูู Rate Limiting:

```python
# ูู project/settings/base.py
"DEFAULT_THROTTLE_RATES": {
    "ai_agent_user": "20/minute",  # ุฒูุงุฏุฉ ุฅูู 20
    "ai_agent_anon": "10/minute",  # ุฒูุงุฏุฉ ุฅูู 10
}
```

---

## ๐ฏ **ุงููุชูุฌุฉ ุงููุชููุนุฉ:**

ุจุนุฏ ุงูุชุทุจูู:
- โ ุฑุณุงุฆู ุฎุทุฃ ูุงุถุญุฉ ุจุงูุนุฑุจูุฉ
- โ ุญูุงูุฉ ูู ุชุฌุงูุฒ ุญุฏูุฏ OpenAI
- โ ุชุฌุฑุจุฉ ูุณุชุฎุฏู ุฃูุถู
- โ ุชูููู ุฃุฎุทุงุก 429

---

## ๐ **ูููุฒูุฏ ูู ุงูุชุญุณููุงุช:**

1. **Implement Caching** - ูุชูููู ุงูุทูุจุงุช ุงููุชูุฑุฑุฉ
2. **Queue System** - ููุนุงูุฌุฉ ุชุณูุณููุฉ
3. **Multiple API Keys** - ูุชูุฒูุน ุงูุญูู
4. **Upgrade OpenAI Plan** - ูุญุฏูุฏ ุฃุนูู

---

**ุขุฎุฑ ุชุญุฏูุซ:** 16 ุฃูุชูุจุฑ 2025  
**ุงูุญุงูุฉ:** โ ุชู ุชุทุจูู ุงูุญููู ุงูุฃุณุงุณูุฉ

